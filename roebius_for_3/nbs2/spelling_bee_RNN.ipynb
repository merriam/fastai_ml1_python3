{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spelling Bee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook starts our deep dive (no pun intended) into NLP by introducing sequence-to-sequence learning on Spelling Bee."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Stuff\n",
    "\n",
    "We take our data set from [The CMU pronouncing dictionary](https://en.wikipedia.org/wiki/CMU_Pronouncing_Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:08:58.319902Z",
     "start_time": "2017-09-20T12:08:58.308938Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import importlib\n",
    "import utils2; importlib.reload(utils2)\n",
    "from utils2 import *\n",
    "np.set_printoptions(4)\n",
    "PATH = 'data/spellbee/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:08:58.344581Z",
     "start_time": "2017-09-20T12:08:58.322581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limit_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:08:58.363806Z",
     "start_time": "2017-09-20T12:08:58.347006Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CMU pronouncing dictionary consists of sounds/words and their corresponding phonetic description (American pronunciation).\n",
    "\n",
    "The phonetic descriptions are a sequence of phonemes. Note that the vowels end with integers; these indicate where the stress is.\n",
    "\n",
    "Our goal is to learn how to spell these words given the sequence of phonemes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preparation of this data set follows the same pattern we've seen before for NLP tasks.\n",
    "\n",
    "Here we iterate through each line of the file and grab each word/phoneme pair that starts with an uppercase letter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:08:58.955876Z",
     "start_time": "2017-09-20T12:08:58.365879Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('A', ['AH0']), ('ZYWICKI', ['Z', 'IH0', 'W', 'IH1', 'K', 'IY0']))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = [l.strip().split(\"  \") for l in open(PATH+\"cmudict-0.7b\", encoding='latin1') \n",
    "         if re.match('^[A-Z]', l)]\n",
    "lines = [(w, ps.split()) for w, ps in lines]\n",
    "lines[0], lines[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we're going to get a list of the unique phonemes in our vocabulary, as well as add a null \"_\" for zero-padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:08:59.086575Z",
     "start_time": "2017-09-20T12:08:58.957622Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_', 'AA0', 'AA1', 'AA2', 'AE0']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonemes = [\"_\"] + sorted(set(p for w, ps in lines for p in ps))\n",
    "phonemes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:08:59.091544Z",
     "start_time": "2017-09-20T12:08:59.088239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phonemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create mappings of phonemes and letters to respective indices.\n",
    "\n",
    "Our letters include the padding element \"_\", but also \"*\" which we'll explain later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:08:59.120185Z",
     "start_time": "2017-09-20T12:08:59.093018Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p2i = dict((v, k) for k,v in enumerate(phonemes))\n",
    "letters = \"_abcdefghijklmnopqrstuvwxyz*\"\n",
    "l2i = dict((v, k) for k,v in enumerate(letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a dictionary mapping words to the sequence of indices corresponding to it's phonemes, and let's do it only for words between 5 and 15 characters long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:08:59.548659Z",
     "start_time": "2017-09-20T12:08:59.122104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108006"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen=15\n",
    "pronounce_dict = {w.lower(): [p2i[p] for p in ps] for w, ps in lines\n",
    "                 if (5<=len(w)<=maxlen) and re.match(\"^[A-Z]+$\", w)}\n",
    "len(pronounce_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside on various approaches to python's list comprehension:\n",
    "* the first list is a typical example of a list comprehension subject to a conditional\n",
    "* the second is a list comprehension inside a list comprehension, which returns a list of list\n",
    "* the third is similar to the second, but is read and behaves like a nested loop\n",
    "    * Since there is no inner bracket, there are no lists wrapping the inner loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:08:59.559507Z",
     "start_time": "2017-09-20T12:08:59.551261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['XYZ'], [['x', 'y', 'z'], ['a', 'b', 'c']], ['x', 'y', 'z', 'a', 'b', 'c'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=['xyz','abc']\n",
    "[o.upper() for o in a if o[0]=='x'], [[p for p in o] for o in a], [p for o in a for p in o]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split lines into words, phonemes, convert to indexes (with padding), split into training, validation, test sets. Note we also find the max phoneme sequence length for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:08:59.627767Z",
     "start_time": "2017-09-20T12:08:59.561599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxlen_p = max([len(v) for k,v in pronounce_dict.items()])\n",
    "maxlen_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:09:00.350194Z",
     "start_time": "2017-09-20T12:08:59.629409Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs = np.random.permutation(list(pronounce_dict.keys()))\n",
    "n = len(pairs)\n",
    "input_ = np.zeros((n, maxlen_p), np.int32)\n",
    "labels_ = np.zeros((n, maxlen), np.int32)\n",
    "\n",
    "for i, k in enumerate(pairs):\n",
    "    for j, p in enumerate(pronounce_dict[k]): input_[i][j] = p\n",
    "    for j, letter in enumerate(k): labels_[i][j] = l2i[letter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:09:00.358049Z",
     "start_time": "2017-09-20T12:09:00.351810Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "go_token = l2i[\"*\"]\n",
    "dec_input_ = np.concatenate([np.ones((n,1)) * go_token, labels_[:,:-1]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn's <tt>train_test_split</tt> is an easy way to split data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:09:00.409756Z",
     "start_time": "2017-09-20T12:09:00.359768Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(input_train, input_test, labels_train, labels_test, dec_input_train, dec_input_test\n",
    "    ) = train_test_split(input_, labels_, dec_input_, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:09:00.436228Z",
     "start_time": "2017-09-20T12:09:00.411384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97205, 15)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:09:00.474627Z",
     "start_time": "2017-09-20T12:09:00.437696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97205, 15)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:09:00.503748Z",
     "start_time": "2017-09-20T12:09:00.476866Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 28)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_vocab_size, output_vocab_size = len(phonemes), len(letters)\n",
    "input_vocab_size, output_vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we proceed to build our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:09:00.531894Z",
     "start_time": "2017-09-20T12:09:00.505732Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parms = {'verbose': 0, 'callbacks': [TQDMNotebookCallback(leave_inner=True)]}\n",
    "lstm_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:09:00.558719Z",
     "start_time": "2017-09-20T12:09:00.533886Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dim = 240"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:09:00.599925Z",
     "start_time": "2017-09-20T12:09:00.560939Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_rnn(return_sequences= True): \n",
    "    return LSTM(dim, dropout=0.1, recurrent_dropout=0.1, \n",
    "               implementation=1, return_sequences=return_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has three parts:\n",
    "* We first pass list of phonemes through an embedding function to get a list of phoneme embeddings. Our goal is to turn this sequence of embeddings into a single distributed representation that captures what our phonemes say.\n",
    "* Turning a sequence into a representation can be done using an RNN. This approach is useful because RNN's are able to keep track of state and memory, which is obviously important in forming a complete understanding of a pronunciation.\n",
    "    * <tt>BiDirectional</tt> passes the original sequence through an RNN, and the reversed sequence through a different RNN and concatenates the results. This allows us to look forward and backwards.\n",
    "    * We do this because in language things that happen later often influence what came before (i.e. in Spanish, \"el chico, la chica\" means the boy, the girl; the word for \"the\" is determined by the gender of the subject, which comes after).\n",
    "* Finally, we arrive at a vector representation of the sequence which captures everything we need to spell it. We feed this vector into more RNN's, which are trying to generate the labels. After this, we make a classification for what each letter is in the output sequence.\n",
    "    * We use <tt>RepeatVector</tt> to help our RNN remember at each point what the original word is that it's trying to translate.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:09:02.224145Z",
     "start_time": "2017-09-20T12:09:00.602155Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inp = Input((maxlen_p,))\n",
    "x = Embedding(input_vocab_size, 120)(inp)\n",
    "\n",
    "x = Bidirectional(get_rnn())(x)\n",
    "x = get_rnn(False)(x)\n",
    "\n",
    "x = RepeatVector(maxlen)(x)\n",
    "x = get_rnn()(x)\n",
    "x = get_rnn()(x)\n",
    "x = TimeDistributed(Dense(output_vocab_size, activation='softmax'))(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can refer to the parts of the model before and after <tt>get_rnn(False)</tt> returns a vector as the encoder and decoder. The encoder has taken a sequence of embeddings and encoded it into a numerical vector that completely describes it's input, while the decoder transforms that vector into a new sequence.\n",
    "\n",
    "Now we can fit our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:09:02.227757Z",
     "start_time": "2017-09-20T12:09:02.225458Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inp, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:09:02.320211Z",
     "start_time": "2017-09-20T12:09:02.228958Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(), 'sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:20:42.438301Z",
     "start_time": "2017-09-20T12:09:02.322323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac39572302f4769941478f50e7769af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcde1d3a3bee4ca29210ef66ea2182f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f3a02bc54c64856a96c800afc2bb4b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7801a36819c4792a56e8debede4c8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(input_train, np.expand_dims(labels_train,-1), \n",
    "          validation_data=[input_test, np.expand_dims(labels_test,-1)], \n",
    "          batch_size=64, **parms, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:20:42.445820Z",
     "start_time": "2017-09-20T12:20:42.440452Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.3335904966691128, 0.78262739762168565, 0.59394923120436316]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate, we don't want to know what percentage of letters are correct but what percentage of words are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:20:42.470433Z",
     "start_time": "2017-09-20T12:20:42.448818Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_keras(input):\n",
    "    preds = model.predict(input, batch_size=128)\n",
    "    predict = np.argmax(preds, axis = 2)\n",
    "    return (np.mean([all(real==p) for real, p in zip(labels_test, predict)]), predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy isn't great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:20:46.646446Z",
     "start_time": "2017-09-20T12:20:42.472136Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.088047403018239045"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, preds = eval_keras(input_test); acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:20:46.660870Z",
     "start_time": "2017-09-20T12:20:46.648462Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_examples(preds):\n",
    "    print(\"pronunciation\".ljust(40), \"real spelling\".ljust(17), \n",
    "          \"model spelling\".ljust(17), \"is correct\")\n",
    "\n",
    "    for index in range(20):\n",
    "        ps = \"-\".join([phonemes[p] for p in input_test[index]]) \n",
    "        real = [letters[l] for l in labels_test[index]] \n",
    "        predict = [letters[l] for l in preds[index]]\n",
    "        print(ps.split(\"-_\")[0].ljust(40), \"\".join(real).split(\"_\")[0].ljust(17),\n",
    "            \"\".join(predict).split(\"_\")[0].ljust(17), str(real == predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that sometimes the mistakes are completely reasonable, occasionally they're totally off. This tends to happen with the longer words that have large phoneme sequences.\n",
    "\n",
    "That's understandable; we'd expect larger sequences to lose more information in an encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:20:46.715096Z",
     "start_time": "2017-09-20T12:20:46.663398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pronunciation                            real spelling     model spelling    is correct\n",
      "G-EH1-SH-K                               geschke           gesck             False\n",
      "M-AH0-K-M-ER1-IY0                        mcmurrey          mcmorry           False\n",
      "R-OW1-Z-ER0                              rowser            roserr            False\n",
      "K-AA2-N-JH-AH0-G-EY1-SH-AH0-N            conjugation       congegatton       False\n",
      "AO0-L-EH1-T-AH0                          auletta           olltta            False\n",
      "L-AO1-L-IY0                              lawley            lolley            False\n",
      "V-AE2-N-S-IH1-K-AH0-L                    vansickel         vansicall         False\n",
      "T-R-AE1-M-P-T                            tramped           tramped           True\n",
      "K-OW1-L-EH1-T                            colette           collttt           False\n",
      "R-IY1-M-AE1-CH                           rematch           remmcch           False\n",
      "P-R-AA0-G-N-OW1-S-AH0-S                  prognosis         prognnssss        False\n",
      "OW2-V-ER0-W-IH1-N-T-ER0                  overwinter        overrnnter        False\n",
      "HH-AY1-S-M-AH0-N                         heisman           heismaan          False\n",
      "W-IY1-K-AH0-N-IH0-NG                     weakening         weichniigg        False\n",
      "AE2-N-AH0-L-IH1-T-IH0-K-S                analytics         analltiics        False\n",
      "M-AH0-L-EY1-ZH-AH0-N-Z                   malaysians        malaiions         False\n",
      "S-K-EY1-T                                skate             scatt             False\n",
      "V-AE2-N-D-IY1-V-ER0                      vandever          vandeverr         False\n",
      "CH-AA1-P-S-UW1-IY0                       chopsuey          chapsiy           False\n",
      "M-AH0-K-AO1-L                            mccall            mccoll            False\n"
     ]
    }
   ],
   "source": [
    "print_examples(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph demonstrates the accuracy decay for a neural translation task. With an encoding/decoding technique, larger input sequences result in less accuracy.\n",
    "\n",
    "<img src=\"https://smerity.com/media/images/articles/2016/bahdanau_attn.png\" width=\"600\">\n",
    "\n",
    "This can be mitigated using an attentional model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:20:46.730063Z",
     "start_time": "2017-09-20T12:20:46.717209Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import attention_wrapper; importlib.reload(attention_wrapper)\n",
    "from attention_wrapper import Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attentional model doesn't encode into a single vector, but rather a sequence of vectors. The decoder then at every point is passing through this sequence. For example, after the bi-directional RNN we have 16 vectors corresponding to each phoneme's output state. Each output state describes how each phoneme relates between the other phonemes before and after it. After going through more RNN's, our goal is to transform this sequence into a vector of length 15 so we can classify into characters. \n",
    "\n",
    "A smart way is to take a weighted average of the 16 vectors for each of the 15 outputs, where each set of weights is unique to the output. For example, if character 1 only needs information from the first phoneme vector, that weight might be 1 and the others 0; if it needed information from the 1st and 2nd equally, those two might be 0.5 each.\n",
    "\n",
    "The weights for combining all the input states to produce specific outputs can be learned using an attentional model; we update the weights using SGD, and train it jointly with the encoder/decoder. Once we have the outputs, we can classify the character using softmax as usual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice below we do not have an RNN that returns a flat vector as we did before; we have a sequence of vectors as desired. We can then pass a sequence of encoded states into the our custom <tt>Attention</tt> model.\n",
    "\n",
    "This attention model also uses a technique called teacher forcing; in addition to passing the encoded hidden state, we also pass the correct answer for the previous time period. We give this information to the model because it makes it easier to train. In the beginning of training, the model will get most things wrong, and if your earlier character predictions are wrong then your later ones will likely be as well. Teacher forcing allows the model to still learn how to predict later characters, even if the earlier characters were all wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:20:46.762409Z",
     "start_time": "2017-09-20T12:20:46.732057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((97205, 16), (97205, 15))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_train.shape, dec_input_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:20:49.045666Z",
     "start_time": "2017-09-20T12:20:46.763924Z"
    },
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inp = Input((maxlen_p,))\n",
    "inp_dec = Input((maxlen,))\n",
    "emb_dec = Embedding(output_vocab_size, 120)(inp_dec)\n",
    "emb_dec = Dense(dim)(emb_dec)\n",
    "\n",
    "x = Embedding(input_vocab_size, 120)(inp)\n",
    "x = Bidirectional(get_rnn())(x)\n",
    "x = get_rnn()(x)\n",
    "x = get_rnn()(x)\n",
    "x = Attention(get_rnn, 3)([x, emb_dec])\n",
    "x = TimeDistributed(Dense(output_vocab_size, activation='softmax'))(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train, passing in the decoder inputs as well for teacher forcing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:20:49.094198Z",
     "start_time": "2017-09-20T12:20:49.047345Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([inp, inp_dec], x)\n",
    "model.compile(Adam(), 'sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:38:04.028792Z",
     "start_time": "2017-09-20T12:20:49.096097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec0220ab51e4bb4bf44a93b38dc00af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5735ce204f22445e88fde685cbab4673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6479099dcf5e4d01a87bcecc1ddc521a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab17233d8aa341978d5d6b60e239c81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit([input_train, dec_input_train], np.expand_dims(labels_train,-1), \n",
    "          validation_data=[[input_test, dec_input_test], np.expand_dims(labels_test,-1)], \n",
    "          batch_size=64, **parms, epochs=3)  # Keras 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:38:04.036557Z",
     "start_time": "2017-09-20T12:38:04.031384Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0782053908444413, 0.74466206967063597, 0.3586209160361552]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T12:38:04.510738Z",
     "start_time": "2017-09-20T12:38:04.039034Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.set_value(model.optimizer.lr, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T13:06:44.466147Z",
     "start_time": "2017-09-20T12:38:04.512451Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roebius/pj/p3/lib/python3.5/site-packages/ipykernel/__main__.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe4ba550a9546fd8494bcb4fa09106d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe97788df474999ae8fd05076141c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      "97152/|/[loss: 0.329, acc: 0.896] 100%|| 97152/97205 [05:40<00:00, 298.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00381840655541e295afa3b269d841d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f132c83efbc14725828b5f6ef7851583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      "97152/|/[loss: 0.281, acc: 0.911] 100%|| 97152/97205 [05:42<00:00, 294.89it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77e08e6fcfd45de9c1a5986aef3f939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d85d1ea8c144c4eba4e32ff7b9d9cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit([input_train, dec_input_train], np.expand_dims(labels_train,-1), \n",
    "          validation_data=[[input_test, dec_input_test], np.expand_dims(labels_test,-1)], \n",
    "          batch_size=64, **parms, epochs=5)  # Keras 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T13:06:44.473794Z",
     "start_time": "2017-09-20T13:06:44.468619Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2908,  0.2707,  0.2547,  0.2411,  0.2316])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T13:06:44.496499Z",
     "start_time": "2017-09-20T13:06:44.475959Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_keras():\n",
    "    preds = model.predict([input_test, dec_input_test], batch_size=128)\n",
    "    predict = np.argmax(preds, axis = 2)\n",
    "    return (np.mean([all(real==p) for real, p in zip(labels_test, predict)]), predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T13:06:51.722786Z",
     "start_time": "2017-09-20T13:06:44.499033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33135820757337281"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, preds = eval_keras(); acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is certainly performing better with longer words. The mistakes it's making are reasonable, and it even succesfully formed the word \"partisanship\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T13:06:51.762095Z",
     "start_time": "2017-09-20T13:06:51.725296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pronunciation                            real spelling     model spelling    is correct\n",
      "G-EH1-SH-K                               geschke           geschke           True\n",
      "M-AH0-K-M-ER1-IY0                        mcmurrey          mcmerryy          False\n",
      "R-OW1-Z-ER0                              rowser            rosser            False\n",
      "K-AA2-N-JH-AH0-G-EY1-SH-AH0-N            conjugation       conjugation       True\n",
      "AO0-L-EH1-T-AH0                          auletta           alletta           False\n",
      "L-AO1-L-IY0                              lawley            lawley            True\n",
      "V-AE2-N-S-IH1-K-AH0-L                    vansickel         vansicall         False\n",
      "T-R-AE1-M-P-T                            tramped           tramped           True\n",
      "K-OW1-L-EH1-T                            colette           colette           True\n",
      "R-IY1-M-AE1-CH                           rematch           remacch           False\n",
      "P-R-AA0-G-N-OW1-S-AH0-S                  prognosis         prognosis         True\n",
      "OW2-V-ER0-W-IH1-N-T-ER0                  overwinter        overwinter        True\n",
      "HH-AY1-S-M-AH0-N                         heisman           hiisman           False\n",
      "W-IY1-K-AH0-N-IH0-NG                     weakening         weikening         False\n",
      "AE2-N-AH0-L-IH1-T-IH0-K-S                analytics         analitics         False\n",
      "M-AH0-L-EY1-ZH-AH0-N-Z                   malaysians        malazaions        False\n",
      "S-K-EY1-T                                skate             scate             False\n",
      "V-AE2-N-D-IY1-V-ER0                      vandever          vandiver          False\n",
      "CH-AA1-P-S-UW1-IY0                       chopsuey          chapsui           False\n",
      "M-AH0-K-AO1-L                            mccall            mccall            True\n"
     ]
    }
   ],
   "source": [
    "print(\"pronunciation\".ljust(40), \"real spelling\".ljust(17), \n",
    "      \"model spelling\".ljust(17), \"is correct\")\n",
    "\n",
    "for index in range(20):\n",
    "    ps = \"-\".join([phonemes[p] for p in input_test[index]]) \n",
    "    real = [letters[l] for l in labels_test[index]] \n",
    "    predict = [letters[l] for l in preds[index]]\n",
    "    print (ps.split(\"-_\")[0].ljust(40), \"\".join(real).split(\"_\")[0].ljust(17),\n",
    "        \"\".join(predict).split(\"_\")[0].ljust(17), str(real == predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Test code for the attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T13:17:59.873149Z",
     "start_time": "2017-09-20T13:17:59.869118Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_samples, nb_time, input_dim, output_dim = (64, 4, 32, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T13:18:00.515449Z",
     "start_time": "2017-09-20T13:18:00.510386Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(np.float32, (nb_samples, nb_time, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T13:18:01.188730Z",
     "start_time": "2017-09-20T13:18:01.182024Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xr = K.reshape(x,(-1,nb_time,1,input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T13:18:01.837647Z",
     "start_time": "2017-09-20T13:18:01.830010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(32), Dimension(32)])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1 = tf.placeholder(np.float32, (input_dim, input_dim)); W1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T13:18:03.212797Z",
     "start_time": "2017-09-20T13:18:03.206084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1r = K.reshape(W1, (1, input_dim, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T13:18:03.794746Z",
     "start_time": "2017-09-20T13:18:03.788311Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1r2 = K.reshape(W1, (1, 1, input_dim, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-20T13:19:12.839753Z",
     "start_time": "2017-09-20T13:19:12.816235Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "number of input channels does not match corresponding dimension of filter, 4 != 32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-3970cac2a8b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxW1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW1r2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mxW1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m  \u001b[0;31m# Keras 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/pj/p3/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(x, kernel, strides, padding, data_format, dilation_rate)\u001b[0m\n\u001b[1;32m   3114\u001b[0m         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3115\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3116\u001b[0;31m         data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   3117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pj/p3/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(input, filter, padding, strides, dilation_rate, name, data_format)\u001b[0m\n\u001b[1;32m    648\u001b[0m           \u001b[0;34m\"number of input channels does not match corresponding dimension of filter, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m           \"{} != {}\".format(input_channels_dim, filter.get_shape()[\n\u001b[0;32m--> 650\u001b[0;31m               num_spatial_dims]))\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m     strides, dilation_rate = _get_strides_and_dilation_rate(\n",
      "\u001b[0;31mValueError\u001b[0m: number of input channels does not match corresponding dimension of filter, 4 != 32"
     ]
    }
   ],
   "source": [
    "xW1 = K.conv1d(x,W1r,padding='same'); xW1.shape  # Keras 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T17:04:58.337118Z",
     "start_time": "2017-09-15T17:04:58.327911Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xW12 = K.conv2d(xr,W1r2,padding='same'); xW12.shape  # Keras 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T17:05:00.234611Z",
     "start_time": "2017-09-15T17:05:00.216830Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xW2 = K.dot(x, W1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T17:05:01.989204Z",
     "start_time": "2017-09-15T17:05:01.984461Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = np.random.normal(size=(nb_samples, nb_time, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T17:05:03.340616Z",
     "start_time": "2017-09-15T17:05:03.336211Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w1 = np.random.normal(size=(input_dim, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T17:05:04.352840Z",
     "start_time": "2017-09-15T17:05:04.343350Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()  # - added this lines to use a TF session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T17:05:09.051203Z",
     "start_time": "2017-09-15T17:05:09.030864Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = sess.run(xW1, {x:x1, W1:w1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T17:05:12.389653Z",
     "start_time": "2017-09-15T17:05:11.432142Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res2 = sess.run(xW2, {x:x1, W1:w1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T17:05:13.756961Z",
     "start_time": "2017-09-15T17:05:13.736034Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.allclose(res, res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T17:05:15.615415Z",
     "start_time": "2017-09-15T17:05:15.608347Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2 = tf.placeholder(np.float32, (output_dim, input_dim)); W2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T17:05:16.556811Z",
     "start_time": "2017-09-15T17:05:16.552563Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = tf.placeholder(np.float32, (nb_samples, output_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T17:05:17.133862Z",
     "start_time": "2017-09-15T17:05:17.126894Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hW2 = K.dot(h,W2); hW2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T17:05:17.591200Z",
     "start_time": "2017-09-15T17:05:17.582583Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hW2 = K.reshape(hW2,(-1,1,1,input_dim)); hW2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "p3",
   "language": "python",
   "name": "p3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
